# ğŸš€ Quick Start Guide - Livestock Vision AI

## Step-by-Step Instructions

### 1. Create Environment File

Create a file named `.env` in this directory (`livestock-monitoring`) with:

```env
VITE_API_URL=http://localhost:8000
```

### 2. Start the Backend API

Open a **new terminal** and run:

```bash
cd C:\Users\Jojo\Desktop\livestock-api\livestock-infer
uvicorn app:app --reload
```

You should see:
```
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
Loading ONNX model from: models/best.onnx
Model loaded successfully!
```

### 3. Start the Frontend

In **another terminal**, run:

```bash
cd C:\Users\Jojo\Desktop\livestock-monitoring
npm run dev
```

You should see:
```
  VITE v5.x.x  ready in xxx ms

  âœ  Local:   http://localhost:5173/
  âœ  Network: use --host to expose
```

### 4. Open the Application

Open your browser and go to: **http://localhost:5173**

## ğŸ¯ Testing the Application

1. **Check Dashboard**
   - The dashboard should show "Status: ok" with green checkmark
   - If you see an error, make sure the backend is running

2. **Upload an Image**
   - Click on "ğŸ“· Image Analysis" tab
   - Click "Upload Image" and select a livestock image
   - Click "Analyze Image"
   - You should see bounding boxes around detected animals

3. **View History**
   - Click on "ğŸ“‹ History" tab
   - See all previous detections
   - Delete detections if needed

## âš ï¸ Troubleshooting

### "Backend Connection Failed"
- âœ… Make sure backend is running on port 8000
- âœ… Check that `.env` file exists with correct API URL
- âœ… Restart both backend and frontend

### "Internal Server Error" on Image Upload
- âœ… Check backend terminal for error messages
- âœ… Verify ONNX model is loaded correctly
- âœ… Try a different image format (JPG or PNG)

### Port Already in Use
- **Frontend (5173):** Vite will automatically use next available port
- **Backend (8000):** Kill existing process or change port

## ğŸ“ Directory Structure

```
livestock-monitoring/          â† Frontend (React + TypeScript)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                  â† API service
â”‚   â”œâ”€â”€ components/           â† React components
â”‚   â”œâ”€â”€ App.tsx              â† Main app
â”‚   â””â”€â”€ main.tsx             â† Entry point
â”œâ”€â”€ .env                     â† Configuration (create this!)
â””â”€â”€ package.json

livestock-api/livestock-infer/ â† Backend (FastAPI + ONNX)
â”œâ”€â”€ app.py                   â† Main API (with CORS enabled)
â”œâ”€â”€ models/best.onnx         â† YOLO model
â”œâ”€â”€ database.py              â† Database logic
â””â”€â”€ config.py                â† Configuration
```

## ğŸ¨ Features

âœ¨ **Dashboard** - System health and model info
âœ¨ **Image Analysis** - Upload and detect livestock
âœ¨ **Detection History** - View and manage detections
âœ¨ **Real-time Feedback** - Bounding boxes with confidence scores
âœ¨ **Responsive Design** - Works on desktop and tablet

## ğŸ”§ Technologies Used

**Frontend:**
- React 19 + TypeScript
- Vite (build tool)
- Tailwind CSS (styling)

**Backend:**
- FastAPI (Python)
- ONNX Runtime (AI inference)
- MySQL/SQLite (database)

## ğŸ“ Need Help?

Check the detailed README_SETUP.md file for more information!

